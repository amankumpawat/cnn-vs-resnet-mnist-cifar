# deep-learning-classification-mnist-cifar10

A fully built-from-scratch deep learning project evaluating resnet-18, cnn, and no-skip variants on mnist and cifar-10. includes black-box and white-box testing, weight visualizations, hyperparameter tuning, and complete model analysis with formatted outputs and visuals.

### ğŸ” End-to-End Training, Evaluation & Visualization using ResNet-18, CNN, and No-Skip Variants

This project was created for a senior capstone in deep learning. All models were built and trained **from scratch** using PyTorch and evaluated across multiple datasets. Visuals were carefully integrated to analyze training, predictions, weights, and testing phases.

---

## Models Implemented

- âœ… ResNet-18 (for MNIST)
- âœ… ResNet-18 (for CIFAR-10)
- âœ… Baseline CNN (no skip connections, CIFAR-10)
- âœ… ResNet-18 No-Skip (Ablation variant)

---

## Visualizations Included

- ğŸ“ˆ Training Accuracy & Loss (linear + log scale)
- ğŸ”¢ Confusion Matrices (all models)
- ğŸ§  Correct vs Incorrect Predictions
- ğŸ“‰ Prediction Probability Bar Charts (softmax)
- ğŸ› Model Summary Tables (torchsummary)
- ğŸ¨ Conv1 Filters & FC Layer Weight Matrices
- ğŸ“‹ Hyperparameter Tuning Tables (best/worst)

---

## Requirements

```bash
pip install torch torchvision matplotlib seaborn torchsummary
